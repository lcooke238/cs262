# COMPSCI 262 Pset 2: Lab Notebook

## Prompt
Examine logs and discuss the size of jumps in the vals for the logical clocks, drift in the vals of the local logical clocks in the different machines (compared to system time), and the impact different timings on such things as gaps in the logical clock vals and length of the msg queue. Include observations and reflections abt the model and the results of running the model.

## Experiment 1: Default
For our first experiment, we ran our mock system with three connected machines for a minute five separate times, keeping the logs from the most interesting of these runs in the ```../logs/experiment_1``` folder. Our clock randomization was in the default 1-6 range and our machine action randomization was also in the default 1-10 range. Here is what we found:

- **General Observations**: Here, we see that the faster the machine, the longer the log as it was able to do more things in the same amount of time. We also see that slower machines spend more time recieving messages, as they recieve lots of messages from faster machines and are required to get through them all before they can do anything else.
- **Jump Size**: The jump sizes between logical clock values were pretty consistent across the board. In increasing speed order, the machine with clock speed 1 had an average jump of 3.87, a min jump of 1, and a max jump of 17; the machine with clock speed 3 had an average jump of 1.95, a min jump of 1, and a max jump of 13; and the machine with clock speed 6 had an average jump of 1, a min jump of 1, and a max jump of 1. As a result, we see that generally as speed increases, the average jump size decreases because less can occur between operations for a faster machine. 
- **Value Drift**: I saw a similar trend with respect to value drift, where the fastest machine had an extremely consistent dif between logical clock and system time around -0.830, the mid-speed machine with an average dif around -1.61, and the slowest machine with a dif around -2.865. The min drift values corresponded quite well with the max jump values from the previous point as well, with the fastest machine sitting right around its average at -0.833, the mid-speed machine sitting at -12.665, and the slowest machine at -16. As a result, we see that generally as speed increases, like with jump size, value drift also decreases because less can occur between logical time steps. One interesting insight as well is that drift can occur in both directions, meaning that average drift will not necessarily capture the general pattern of increasing magnitude of drift with extremely slow machines (ie. machine with speed 1 had a max drift of 0.005 potentially indicative of a greater trend).
- **length of message queue**: Here, we see a drastic difference in message queue length between the different machines. The fast and mid-speed machines were relatively comprable, with the fastest machine always having a 0 length queue after removing a message, the mid-spped machine mostly having a 0 length queue with the occasional 1-length from two messages being sent between the same step. However, the slowest machine never had a chance to send messages, as it would get overwhelmed with messages from the faster machines and they would back up in its queue, leading to queue lengths as high as 39. 
- **Visual analysis**; Graphing the three machines' local logical clock times over actual running time makes the interrelation between their times much clearer; you can find this graph toward the bottom of analysis.ipynb. As we'll see throughout all of our graphs, the machine with the highest clock time sets the de facto standard for the rest; no machine is ever able to report a higher time than that with the highest clock rate, so its local time vs. global time line always looks totally linear. The machine with a clock speed of 3 keeps up nicely under these hyperparameters; the machine with a clock speed of 1 straggles significantly, which is due to the length of its message queue as discussed above. By the time we hit a minute, machine 2 has about 30 messages queued, but can only take them out once per second, resulting in its desynchronization with the other two machines.


## Experiment 2: identical clock cycles
For this experiment, we ran our mock system with three connected machines for a minute five separate times. Our machine randomization remained the same (between 1 and 10), however our clock randomization ceased to be random, and all machines ran with the same speed of 2. Here is what we found:

- **General Observations**: Given our results from experiment 1 establishing a correlation between speed and our characteristics of interest and knowing to ignore the bottom few lines of each logfile in the analysis, I would expect general drift, jump size, and message queue lengths to be roughly consistent between machines.
- **Jump Size**: Here, the jump size was exactly what I expected, with machine 0 producing an average jump of 1.109, a min of 1, and a max of 3; machine 1 producing an average jump of 1.107, a min of 1, and a max of 3; and machine 2 producing an average jump of 1.109, a min of 1, and a max of 3. This supports the conclusions I drew from experiment 1, in that the jump size is tied to the speed of each machine.
- **Value Drift**: We see a similar trend for value drift, as all three machines have an average drift of around -0.7 and a min drift of around -2.66. This also supports the conclusions I drew from experiment 1, in that the value drift, like jump size, is tied to the speed of each machine.
- **length of message queue**: again, we also notice that the queue length is quite consistent between machines, with all queries per machine sitting at 0 execpt for 4, which sit at 1. This extremely consistent metric supports the fact that evenly speedy machines will have more consistent results than systems with machines of varying speeds.
- **Visual analysis**: Unsurprising; all three machines exhibit a practically linear local time vs. global time relationship, wriggling around each other tightly.


## Experiment 3: No internal events
For this experiment, we ran our mock system with three connected machines for a minute five separate times. Our clock randomization was the default 1-6 range, however, we removed the possibility of an internal event occuring by keeping the machine randomization between 1 and 3. Here is what we found:

- **General Observations**: Given our results from experiments 1 and 2 establishing a correlation between speed and our characteristics of interest and knowing to ignore the bottom few lines of each logfile in the analysis, I would expect general drift and jump size to be similar to experiment 1 if not a bit lower without internal events to slow increase jumps between communications, while message queue lengths will dramatically pile up (especially in the slowest machine).
- **Jump Size**: Here, the jump sizes between logical clock values were pretty consistent across the board. In increasing speed order, the machine with clock speed 1 had an average jump of 1.59, a min jump of 1, and a max jump of 4; the machine with clock speed 3 had an average jump of 1.49, a min jump of 1, and a max jump of 5; and the machine with clock speed 6 had an average jump of 1, a min jump of 1, and a max jump of 1. As a result, we see that, like in experiment 1, generally as speed increases, the average jump size decreases because less can occur between operations for a faster machine. However, we see the absolutes and averages of the two slower machines are smaller than in experiment 1. This makes sense because without internal events to increment the logical clock without communicating to the other systems, the only time the logical clock can increase without telling a machine about it is if it only sends a message to the other machine, increasing the chance a machine finds out about it and minimizing the gap.
- **Value Drift**: We see an interesting trend with respect to value drift, where the fastest machine had an extremely consistent dif between logical clock and system time around -0.830, the mid-speed machine with an average dif around -1.11, and the slowest machine with a dif around -0.58. I particuarly found the slowest machine the most interesting, as we saw drift in both a positive and a negative direction. This tells us that drift is inconsistent with respect to direction and magnitude, emphasizing the importance of the logical clock for ordering events.
- **length of message queue**: As expected, the queue lengths dramatically increased here, with the slowest machine getting a max length of 196 messages, the mid speed machine around 69, and the only ever sending messages, as the other two machines rapidly became innundated with messages from it. This shows that when you remove internal events, other machines have less time to catch up with the message flow, and the queue sizes pile up very quickly with a difference in speed.
- **Visual analysis**: This is reminiscent of experiment 1, but with more significant straggling from both the machine with clock speed 3 and the machine with clock speed 1. Machine 0's straggling here becomes pretty horrific due to its queue length of ~200 messages by the experiment's conclusion. Since the lack of internal events causes the slower machines' queues to fill up much faster, this significantly desynchronizes our machines, resulting in the rather counterintuitive conclusion that sending more messages between machines does not always necessarily result in higher degrees of synchronicity.

For fun, we've run two more experiments through the visual analysis rigamarole. Again, all these graphs can be found at the bottom of analysis.ipynb;

## Experiment 4: Very rare sends
For this experiment, we ran our mock system with three connected machines for a minute five separate times. We manually set the clock rates of the three machines to 4, 5, and 6, while greatly biasing the machine randomization in favor of internal events by having the random number generated uniformly between 1 and 250. The graph reveals that the machine with clock speed 6 still sets the precedent each other machine reaches toward, while the other two keep relatively close, despite the rarity of send events. There is still some straggling, but desynchronicity is always kept within a reasonable amount; this is perhaps because the message queues for each machine never come into any danger of overfilling, due to the rarity of send events.

This graph also reveals a property of our syncronicity model which is perhaps unintuitive, but easily explainable: namely, that machines with slower clock times can report more recent times than machines with faster ones. Observe the states of the machines at the 20 second mark; machine 0 with clock rate 4 reports a more recent time than machine 1 with clock rate 5. This is because machine 2 with clock rate 6 chose to send to machine 0 and not machine 1 just before the 20 second mark, resulting in a situation where machine 1 would actually learn a more recent time from a send from machine 0.

## Experiment 5: Only internal events
For this experiment, we checked our program produced a predictably boring result given a particularly boring setup; namely, one in which only internal events ever happen, with clock rates 1, 2, and 3. With no send events, the primary functionality of the machine is lost, so we just get three machines ticking along linearly at different rates without a care for each other. Obviously machine 0 reports a final time of 60, machine 1 reports 120, and machine 3 180 after one minute has elapsed; this occurred every time we ran the experiment. Consider this something of a control; jump times between values was always 1, and message queues were always empty.

## Takeaways
Overall, the logical clock model has been quite useful tool for tracking the order of events in a distributed system, allowing us to order events properly without knowing the exact time that they occured on the system. We saw that the size of jumps in the logical clock values can vary depending on the frequency and timing of events, and that the length of the message queue can also vary depending on the frequency and timing of events. We also thought a bit about the limitations of this simulation in understanding network behavior, ignoring things like network latency, message loss, and machine failures that could all impact the ordering of events.